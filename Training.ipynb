{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ArBisHjh9g9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69899698-d5c5-4157-f2fe-1e1940dc22fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Collecting pyswarm\n",
            "  Downloading pyswarm-0.6.tar.gz (4.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Building wheels for collected packages: pyswarm\n",
            "  Building wheel for pyswarm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyswarm: filename=pyswarm-0.6-py3-none-any.whl size=4464 sha256=a183e51f339d97b9460e5616f11a10114bbc167ea5493d018070262ff8eb4d27\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/4f/ec/8970b83323e16aa95034da175454843947376614d6d5e9627f\n",
            "Successfully built pyswarm\n",
            "Installing collected packages: pyswarm\n",
            "Successfully installed pyswarm-0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm pyswarm xgboost scikit-learn pandas numpy imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from pyswarm import pso\n",
        "from imblearn.over_sampling import SMOTE\n"
      ],
      "metadata": {
        "id": "hHQzEoz6mPN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"ðŸ”„ Loading Dataset...\")\n",
        "final_df = pd.read_csv(\"heart_failure_dataset.csv\")\n",
        "\n",
        "\n",
        "X = final_df.drop(columns=['subject_id', 'admittime', 'dischtime', 'dob', 'dod', 'readmission_30d'])\n",
        "y = final_df['readmission_30d']\n",
        "\n",
        "# One-Hot Encoding for categorical variables\n",
        "X = pd.get_dummies(X, columns=['insurance', 'ethnicity', 'gender'], drop_first=True)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE for balancing classes\n",
        "print(\"ðŸ”„ Applying SMOTE for Balancing Data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Standardize features (for Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"âœ… Data Preprocessing Completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9vHkbEGkwXL",
        "outputId": "42584d5d-2873-4c9a-b71e-72f97e1a48be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Loading Dataset...\n",
            "ðŸ”„ Applying SMOTE for Balancing Data...\n",
            "âœ… Data Preprocessing Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Initialize Models\n",
        "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "lr = LogisticRegression(max_iter=500, random_state=42)\n",
        "\n",
        "# Train Models\n",
        "xgb.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "# Evaluate Models\n",
        "def evaluate_model(name, y_true, y_pred, model):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, model.predict_proba(X_test)[:, 1])\n",
        "    print(f\"{name} - Accuracy: {accuracy:.2f}, AUC: {auc:.2f}\")\n",
        "\n",
        "evaluate_model(\"XGBoost\", y_test, y_pred_xgb, xgb)\n",
        "evaluate_model(\"Random Forest\", y_test, y_pred_rf, rf)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqCX7YBwr9tp",
        "outputId": "897dd536-11ba-475f-ebd2-5375f8324670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost - Accuracy: 0.87, AUC: 0.49\n",
            "Random Forest - Accuracy: 0.87, AUC: 0.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def pso_fitness(params, model_type):\n",
        "    params = np.abs(params)  # Ensure parameters are positive\n",
        "\n",
        "    if model_type == \"xgb\":\n",
        "        model = XGBClassifier(n_estimators=int(params[0]), max_depth=int(params[1]), learning_rate=params[2], random_state=42)\n",
        "    elif model_type == \"rf\":\n",
        "        model = RandomForestClassifier(n_estimators=int(params[0]), max_depth=int(params[1]), random_state=42)\n",
        "    else:  # Logistic Regression\n",
        "        model = LogisticRegression(C=params[0], max_iter=500, solver='liblinear', random_state=42)\n",
        "\n",
        "    # Train-Test Split inside PSO\n",
        "    X_train_pso, X_val_pso, y_train_pso, y_val_pso = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    model.fit(X_train_pso, y_train_pso)\n",
        "    auc = roc_auc_score(y_val_pso, model.predict_proba(X_val_pso)[:, 1])\n",
        "\n",
        "    return -auc  # Minimize negative AUC (maximize AUC)\n"
      ],
      "metadata": {
        "id": "B-6tugOhm-bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "projectabspathname = os.path.abspath('projectname.pickle')\n",
        "print(projectabspathname)\n",
        "projectname = 'Training-model.ipynb'\n",
        "projectpickle = open(str(projectabspathname),'wb')\n",
        "pickle.dump(projectname, projectpickle)\n",
        "projectpickle.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6HXdR3uRLiq",
        "outputId": "63497c93-ff83-4d15-b22c-344af311ea1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/projectname.pickle\n"
          ]
        }
      ]
    }
  ]
}